{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41186db5-2fd4-4c64-bad6-42dce2bd7996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark \n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext()\n",
    "spark = pyspark.sql.SparkSession(sc, jsparkSession=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e02be94-682d-4828-ad2f-dc8c03a59ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into dataframe\n",
    "bookChapterDF = spark.read.option(\"inferSchema\", \"true\").option(\"header\", \"true\").csv(\"bookcontents.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d72051e8-5990-487d-824a-f80af5745957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----+\n",
      "|Chapter|                Name|Page|\n",
      "+-------+--------------------+----+\n",
      "|      1|        Introduction|  11|\n",
      "|      2|Basic Engineering...|  19|\n",
      "|      3|Advanced Engineer...|  28|\n",
      "|      4|     Hands On Course|  60|\n",
      "|      5|        Case Studies|  62|\n",
      "|      6|Best Practices Cl...|  73|\n",
      "|      7|130+ Data Sources...|  77|\n",
      "|      8|1001 Interview Qu...|  82|\n",
      "|      9|Recommended Books...|  87|\n",
      "+-------+--------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bookChapterDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e68e5596-6a6b-40c5-b72a-606eae435693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(Chapter=1, Name='Introduction', Page=11)\n",
      "Row(Chapter=2, Name='Basic Engineering Skills', Page=19)\n",
      "Row(Chapter=3, Name='Advanced Engineering Skills', Page=28)\n",
      "Row(Chapter=4, Name='Hands On Course', Page=60)\n",
      "Row(Chapter=5, Name='Case Studies', Page=62)\n"
     ]
    }
   ],
   "source": [
    "# Create RDD\n",
    "bookRDD = bookChapterDF.rdd\n",
    "\n",
    "# Print RDD\n",
    "for row in bookRDD.take(5):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1730717-4ba2-4248-a94e-7c91b7ca8690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, '11/Introduction')\n",
      "(2, '19/Basic Engineering Skills')\n",
      "(3, '28/Advanced Engineering Skills')\n",
      "(4, '60/Hands On Course')\n",
      "(5, '62/Case Studies')\n"
     ]
    }
   ],
   "source": [
    "# Modify RDD\n",
    "splitRDD = bookRDD.map(lambda columns: (columns[0],(str(columns[2]) + \"/\" + columns[1])))\n",
    "\n",
    "# Print modified RDD\n",
    "for row in splitRDD.take(5):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23ffa471-a6d9-4c36-bff4-3cea7fdc4fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|Chapter|            Compound|\n",
      "+-------+--------------------+\n",
      "|      1|     11/Introduction|\n",
      "|      2|19/Basic Engineer...|\n",
      "|      3|28/Advanced Engin...|\n",
      "|      4|  60/Hands On Course|\n",
      "|      5|     62/Case Studies|\n",
      "|      6|73/Best Practices...|\n",
      "|      7|77/130+ Data Sour...|\n",
      "|      8|82/1001 Interview...|\n",
      "|      9|87/Recommended Bo...|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Turn RDD back to dataframe\n",
    "\n",
    "# Create schema\n",
    "from pyspark.sql.types import *\n",
    "compoundSchema = StructType([\n",
    "    StructField(\"Chapter\", IntegerType()),\n",
    "    StructField(\"Compound\", StringType()),\n",
    "])\n",
    "\n",
    "# Create dataframe\n",
    "compoundDF = spark.createDataFrame(splitRDD, compoundSchema)\n",
    "\n",
    "compoundDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69e7ccea-d1d1-4262-9850-d9194e782211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting words\n",
    "\n",
    "# Read file into RDD\n",
    "sectionsRDD = sc.textFile(\"sections_wordcount.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8393c75-8d1c-4776-8b70-91a4507f0ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,1.1,What is this Cookbook\n",
      "1,1.2,Data Engineer vs Data Scientist\n",
      "1,1.3,My Data Science Platform Blueprint\n",
      "1,1.4,Who Companies Need\n",
      "2,2.1,Learn To Code\n"
     ]
    }
   ],
   "source": [
    "# Print RDD\n",
    "for row in sectionsRDD.take(5):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d749ca3-4eb9-4585-89c9-9ce294be2861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '1.1', 'What is this Cookbook']\n",
      "['1', '1.2', 'Data Engineer vs Data Scientist']\n",
      "['1', '1.3', 'My Data Science Platform Blueprint']\n",
      "['1', '1.4', 'Who Companies Need']\n",
      "['2', '2.1', 'Learn To Code']\n"
     ]
    }
   ],
   "source": [
    "# Split each row\n",
    "playRDD = sectionsRDD.map(lambda columns: columns.split(\",\"))\n",
    "\n",
    "# Print RDD\n",
    "for row in playRDD.take(5):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7994977f-6adc-4f4b-8308-8ac930def86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is this Cookbook\n",
      "Data Engineer vs Data Scientist\n",
      "My Data Science Platform Blueprint\n",
      "Who Companies Need\n",
      "Learn To Code\n"
     ]
    }
   ],
   "source": [
    "# take 3rd column\n",
    "selectTextRDD = playRDD.map(lambda columns: columns[2])\n",
    "\n",
    "# Print RDD\n",
    "for row in selectTextRDD.take(5):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67ec1b08-357d-423d-ac51-e03010052004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('What', 1)\n",
      "('is', 1)\n",
      "('this', 1)\n",
      "('Cookbook', 1)\n",
      "('Data', 1)\n"
     ]
    }
   ],
   "source": [
    "# Flatten RDD\n",
    "flatRDD = selectTextRDD.flatMap(lambda text: text.split(\" \")).map(lambda word: (word, 1))\n",
    "\n",
    "# Print RDD\n",
    "for row in flatRDD.take(5):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af5c918e-9703-4f50-9690-796daf0736a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('(AWS)', 1)\n",
      "('(GCP)', 1)\n",
      "('A', 2)\n",
      "('API', 1)\n",
      "('About', 1)\n",
      "('Academic', 1)\n",
      "('Agile', 1)\n",
      "('Airbnb', 1)\n",
      "('Amazon', 2)\n",
      "('And', 6)\n",
      "('Apache', 3)\n",
      "('Articles', 1)\n",
      "('Azure', 1)\n",
      "('BMW', 1)\n",
      "('Baidu', 1)\n",
      "('Blackrock', 1)\n",
      "('Blog', 1)\n",
      "('Blueprint', 1)\n",
      "('Booking.com', 1)\n",
      "('Books', 2)\n"
     ]
    }
   ],
   "source": [
    "# Count words & Sort by key\n",
    "reducedRDD = flatRDD.reduceByKey(lambda v1, v2: v1+v2).sortByKey()\n",
    "\n",
    "# Print RDD\n",
    "for row in reducedRDD.take(20):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f06c3bd7-4d31-4db5-b39f-1f18368228cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|       Word|Count|\n",
      "+-----------+-----+\n",
      "|      (AWS)|    1|\n",
      "|      (GCP)|    1|\n",
      "|          A|    2|\n",
      "|        API|    1|\n",
      "|      About|    1|\n",
      "|   Academic|    1|\n",
      "|      Agile|    1|\n",
      "|     Airbnb|    1|\n",
      "|     Amazon|    2|\n",
      "|        And|    6|\n",
      "|     Apache|    3|\n",
      "|   Articles|    1|\n",
      "|      Azure|    1|\n",
      "|        BMW|    1|\n",
      "|      Baidu|    1|\n",
      "|  Blackrock|    1|\n",
      "|       Blog|    1|\n",
      "|  Blueprint|    1|\n",
      "|Booking.com|    1|\n",
      "|      Books|    2|\n",
      "+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# From RDD to DF\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "wordCountSchema = StructType([\n",
    "    StructField(\"Word\", StringType()),\n",
    "    StructField(\"Count\", IntegerType()),\n",
    "])\n",
    "\n",
    "wordCountDF = spark.createDataFrame(reducedRDD, wordCountSchema)\n",
    "wordCountDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05a556ca-1702-4421-9b31-064c37301d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|       Word|Count|\n",
      "+-----------+-----+\n",
      "|       Data|   48|\n",
      "|    Science|   40|\n",
      "|        And|    6|\n",
      "|   Platform|    3|\n",
      "|     Apache|    3|\n",
      "| Processing|    3|\n",
      "|        and|    3|\n",
      "|          A|    2|\n",
      "|      Learn|    2|\n",
      "|     Amazon|    2|\n",
      "|       Nifi|    2|\n",
      "|      Books|    2|\n",
      "|   Security|    2|\n",
      "|      Cloud|    2|\n",
      "|         To|    2|\n",
      "|    Courses|    2|\n",
      "|    Twitter|    2|\n",
      "|Development|    2|\n",
      "|       What|    2|\n",
      "|     Google|    2|\n",
      "+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wordCountDF.sort(wordCountDF.Count.desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e100d90-028d-4344-8398-85b1b2b7f1c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
